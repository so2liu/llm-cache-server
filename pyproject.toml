[project]
name = "llm-cache-server"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "fastapi==0.111.0",
    "openai==1.58.1",
    "opentelemetry-api>=1.21.0",
    "opentelemetry-exporter-otlp>=1.21.0",
    "opentelemetry-exporter-otlp-proto-http>=1.21.0",
    "opentelemetry-instrumentation-fastapi>=0.42b0",
    "opentelemetry-sdk>=1.21.0",
    "pydantic==2.6.4",
    "python-dotenv==1.0.0",
    "uvicorn==0.29.0",
]
